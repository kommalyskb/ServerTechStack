# Apache Spark for Production

## Spark Streaming application that reads from Kafka
Here is the full code for a Spark Streaming application that reads from Kafka and writes the stream to Minio:

1. Install Apache Spark on your system. You can either install it directly on your machine or deploy it on a cluster using a tool such as Kubernetes.

2. Download the Minio Spark connector from the Minio website or using the following command:
```
wget https://repo1.maven.org/maven2/io/minio/spark-select_2.11/2.1/spark-select_2.11-2.1.jar
```
4. In your Spark application, add the Minio Spark connector to the classpath. You can do this by specifying it as an --jars option when you submit the application or by including it in the spark.jars configuration property in your Spark configuration file.
```
spark-submit --master k8s://https://<LOAD_BALANCER_ADDRESS>:6443 \
  --deploy-mode cluster \
  --name StreamingApp \
  --class com.example.StreamingApp \
  --executor-memory 2g \
  --total-executor-cores 4 \
  --jars spark-select_2.11-2.1.jar \
  StreamingApp.jar
```

5. In your Spark application, you can use the MinioFileSystem class provided by the Minio Spark connector to access files in Minio. You will need to provide the Minio access key, secret key, and endpoint as configuration properties.

Here is an example of how you can use the MinioFileSystem class to read a file from Minio in a Spark application:
```
import org.apache.spark.sql.SparkSession
import org.apache.spark.streaming.{Seconds, StreamingContext}
import org.apache.spark.streaming.kafka010.ConsumerStrategies.Subscribe
import org.apache.spark.streaming.kafka010.LocationStrategies.PreferConsistent
import org.apache.spark.streaming.kafka010._

object StreamingApp {
  def main(args: Array[String]): Unit = {
    // Create the SparkSession and StreamingContext
    val spark = SparkSession.builder
      .appName("StreamingApp")
      .getOrCreate()
    val ssc = new StreamingContext(spark.sparkContext, Seconds(5))

    // Set the Minio access key and secret key
    spark.sparkContext.hadoopConfiguration.set("fs.s3a.access.key", "YOUR_MINIO_ACCESS_KEY")
    spark.sparkContext.hadoopConfiguration.set("fs.s3a.secret.key", "YOUR_MINIO_SECRET_KEY")
    spark.sparkContext.hadoopConfiguration.set("fs.s3a.endpoint", "http://MINIO_ENDPOINT:9000")

    // Set the Kafka parameters
    val kafkaParams = Map[String, Object](
      "bootstrap.servers" -> "KAFKA_BOOTSTRAP_SERVERS",
      "key.deserializer" -> classOf[StringDeserializer],
      "value.deserializer" -> classOf[StringDeserializer],
      "group.id" -> "streaming-group",
      "auto.offset.reset" -> "latest",
      "enable.auto.commit" -> (false: java.lang.Boolean)
    )

    // Subscribe to the Kafka topic
    val topics = Array("kafka-topic")
    val stream = KafkaUtils.createDirectStream[String, String](
      ssc,
      PreferConsistent,
      Subscribe[String, String](topics, kafkaParams)
    )

    // Process the stream
    stream.foreachRDD { rdd =>
      // Convert the RDD to a DataFrame
      val df = spark.read.json(rdd.map(_.value))

      // Write the DataFrame to Minio in the Parquet format
      df.write.mode("append").parquet("s3a://minio-bucket/streaming")

      // Query the data using Spark SQL
      val result = spark.sql("SELECT * FROM parquet.`s3a://minio-bucket/streaming`")
      result.show()
    }

    // Start the streaming context and await termination
    ssc.start()
    ssc.awaitTermination()
  }
}

```
To query the data stored in Minio using Spark SQL, you can use the spark.read.parquet method to read the parquet data into a DataFrame, and then use the usual Spark SQL API to query the data. For example:
```
val df = spark.read.parquet("s3a://minio-bucket/streaming")
df.createOrReplaceTempView("streaming")

val result = spark.sql("SELECT * FROM streaming WHERE value > 10")
result.show()

```

## Deploy Apache Spark
To deploy Apache Spark on Kubernetes using the bitnami/spark image, you can use the following steps as a reference:
1. Create a namespace for your Spark deployment:
```
kubectl create namespace spark
```
2. Set up a persistent volume and persistent volume claim for your Spark deployment. This will be used to store the Spark logs and other data generated by the Spark job.
```
apiVersion: v1
kind: PersistentVolume
metadata:
  name: spark-pv
  namespace: spark
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /mnt/spark
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: spark-pvc
  namespace: spark
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi

```
3. Deploy the Spark master and workers using the bitnami/spark image. The Spark master will be responsible for scheduling and coordinating the Spark jobs, while the Spark workers will execute the tasks.
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-master
  namespace: spark
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark-master
  template:
    metadata:
      labels:
        app: spark-master
    spec:
      containers:
      - name: spark-master
        image: bitnami/spark:latest
        command:
          - "bin/spark-class"
          - "org.apache.spark.deploy.master.Master"
        ports:
        - containerPort: 7077
        - containerPort: 8080
        volumeMounts:
        - name: spark-pvc
          mountPath: /opt/bitnami/spark/logs
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-worker
  namespace: spark
spec:
  replicas: 2
  selector:
    matchLabels:
      app: spark-worker
  template:
    metadata:
      labels:
        app: spark-worker
    spec:
      containers:
      - name: spark-worker
        image: bitnami/spark:latest
        command:
          - "bin/spark-class"
          - "org.apache.spark.deploy.worker.Worker"
          - "spark://spark-master:7077"
        ports:
        - containerPort: 8081
        volumeMounts:
        - name: spark-pvc
          mountPath: /opt/bitnami/spark/logs
```
4. Expose the Spark master UI through an ingress. This will allow you to access the Spark master UI from outside the cluster.
```
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: spark-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: spark.example.com
    http:
      paths:
      - path: /
        backend:
          serviceName: spark-ui
          servicePort: 8080

```